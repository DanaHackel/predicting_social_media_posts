{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Subreddits for Posts from 'The Onion' and 'News' Subreddits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jupyter Notebook 1 - Scrapping posts from both subreddits using the Pushshift API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "#use r/news and r/theonion\n",
    "#followed the primer here https://www.youtube.com/watch?v=AcrjEWsMi_E&feature=youtu.be but turned it into a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://api.pushshift.io/reddit/search/submission'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function to pull post information from reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_posts(subreddit, length):\n",
    "    post_info = [] #A List to collect all scrapped info\n",
    "    utc_date = None \n",
    "    while len(post_info) < length: #Have it keep pulling posts until I get to the desired length\n",
    "        params = {\n",
    "            'size' : 100,\n",
    "            'subreddit': subreddit,\n",
    "            'before': utc_date\n",
    "        }\n",
    "        url = 'https://api.pushshift.io/reddit/search/submission'\n",
    "        res = requests.get(url, params)\n",
    "        data = res.json()\n",
    "        posts = data['data'] \n",
    "        post_info.append(posts) #each list of 100 posts goes into the post_info list\n",
    "        try:\n",
    "            utc_date = posts[99]['created_utc'] #try to call the date of the last post, so the next round of pulled posts are all from before the set that was just pulled\n",
    "        except:\n",
    "            break #this will not work for the last set as there may be less than 100 in the last set pulled\n",
    "        time.sleep(3) #put 3 seconds in between each request to not crash the site\n",
    "    return post_info\n",
    "#While loop idea thanks to Chris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add post info from The Onion to my total list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "onion_posts = pull_posts('theonion', 100)\n",
    "#this will create up to 100 sets of 100 posts from The Onion subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_list = []\n",
    "for x in onion_posts:\n",
    "    for xi in x:\n",
    "        total_list.append(xi)\n",
    "#loop through the list of post lists and add each single post dictionary to the total list of posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7178"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_list) \n",
    "#check that the length is right "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the same steps for the news subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_posts = pull_posts('news', 100)\n",
    "#do the same thing but for r/news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in news_posts:\n",
    "    for xi in x:\n",
    "        total_list.append(xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17178"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the total list a data frame and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_posts = pd.DataFrame(total_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_awardings</th>\n",
       "      <th>allow_live_comments</th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>author_flair_richtext</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>author_flair_type</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>author_patreon_flair</th>\n",
       "      <th>author_premium</th>\n",
       "      <th>...</th>\n",
       "      <th>author_flair_background_color</th>\n",
       "      <th>author_flair_text_color</th>\n",
       "      <th>steward_reports</th>\n",
       "      <th>removed_by</th>\n",
       "      <th>updated_utc</th>\n",
       "      <th>og_description</th>\n",
       "      <th>og_title</th>\n",
       "      <th>gilded</th>\n",
       "      <th>rte_mode</th>\n",
       "      <th>link_flair_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>ManofTheNightsWatch</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_dgjcs</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>dwaxe</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_3jamc</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>Sanlear</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_d0xcf</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>aresef</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_5mtwj</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>aresef</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_5mtwj</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  all_awardings allow_live_comments               author  \\\n",
       "0            []               False  ManofTheNightsWatch   \n",
       "1            []               False                dwaxe   \n",
       "2            []                True              Sanlear   \n",
       "3            []               False               aresef   \n",
       "4            []               False               aresef   \n",
       "\n",
       "  author_flair_css_class author_flair_richtext author_flair_text  \\\n",
       "0                   None                    []              None   \n",
       "1                   None                    []              None   \n",
       "2                   None                    []              None   \n",
       "3                   None                    []              None   \n",
       "4                   None                    []              None   \n",
       "\n",
       "  author_flair_type author_fullname author_patreon_flair author_premium  ...  \\\n",
       "0              text        t2_dgjcs                False          False  ...   \n",
       "1              text        t2_3jamc                False           True  ...   \n",
       "2              text        t2_d0xcf                False           True  ...   \n",
       "3              text        t2_5mtwj                False           True  ...   \n",
       "4              text        t2_5mtwj                False           True  ...   \n",
       "\n",
       "  author_flair_background_color  author_flair_text_color  steward_reports  \\\n",
       "0                           NaN                      NaN              NaN   \n",
       "1                           NaN                      NaN              NaN   \n",
       "2                           NaN                      NaN              NaN   \n",
       "3                           NaN                      NaN              NaN   \n",
       "4                           NaN                      NaN              NaN   \n",
       "\n",
       "   removed_by updated_utc og_description og_title gilded  rte_mode  \\\n",
       "0         NaN         NaN            NaN      NaN    NaN       NaN   \n",
       "1         NaN         NaN            NaN      NaN    NaN       NaN   \n",
       "2         NaN         NaN            NaN      NaN    NaN       NaN   \n",
       "3         NaN         NaN            NaN      NaN    NaN       NaN   \n",
       "4         NaN         NaN            NaN      NaN    NaN       NaN   \n",
       "\n",
       "   link_flair_text  \n",
       "0              NaN  \n",
       "1              NaN  \n",
       "2              NaN  \n",
       "3              NaN  \n",
       "4              NaN  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_posts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17178, 80)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_posts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "all_awardings              3969\n",
       "allow_live_comments        4598\n",
       "author                        0\n",
       "author_flair_css_class    17177\n",
       "author_flair_richtext       116\n",
       "                          ...  \n",
       "og_description            17147\n",
       "og_title                  17147\n",
       "gilded                    16372\n",
       "rte_mode                  17156\n",
       "link_flair_text           16954\n",
       "Length: 80, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_posts.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_posts.to_csv('./data/reddit_posts.csv')\n",
    "#save the dataframe as a csv file in the data folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I scraped posts from 'The Onion' and 'News' subreddits using the Pushshift API. I compiled all the gathered information into one DataFrame and saved it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
